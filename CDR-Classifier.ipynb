{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dc1b213",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers datasets\n",
    "!pip install accelerate -U\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c6473a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "# Increase the maximum number of columns to display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "# Directory where your .csv.gz files are stored\n",
    "directory = './heavy-sequences/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c50147b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n",
      "config.json\n",
      "ERR4077966_Heavy_IGHE.csv.gz\n",
      "checkpoint-1220\n",
      "SRR3099408_Heavy_Bulk.csv.gz\n",
      "pytorch_model.bin\n",
      "checkpoint-2440\n",
      "1279049_1_Heavy_IGHM.csv.gz\n",
      "SRR8283845_1_Heavy_IGHA.csv.gz\n",
      "SRR5811777_1_Heavy_IGHE.csv.gz\n",
      "SRR4297400_Heavy_Bulk.csv.gz\n",
      "checkpoint-3660\n",
      "SRR12326777_1_Heavy_IGHE.csv.gz\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(directory):\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edc98c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store all the dataframes\n",
    "dfs = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv.gz'):  # Only process .csv.gz files\n",
    "        with gzip.open(directory + filename, 'rt') as f:\n",
    "            # Save the first line (metadata) to a variable\n",
    "            metadata = next(f)\n",
    "            # Now load the rest of the file into a DataFrame\n",
    "            df = pd.read_csv(f)\n",
    "\n",
    "            # Define columns to drop\n",
    "            columns_to_drop = [\n",
    "                'locus', 'stop_codon', 'vj_in_frame', 'v_frameshift', 'productive', 'rev_comp', 'complete_vdj', 'v_call',\n",
    "                'd_call', 'j_call', 'sequence_alignment', 'germline_alignment', 'sequence',\n",
    "                'germline_alignment_aa', 'v_alignment_start', 'v_alignment_end', 'd_alignment_start', 'd_alignment_end',\n",
    "                'j_alignment_start', 'j_alignment_end', 'v_sequence_alignment', 'v_sequence_alignment_aa',\n",
    "                'v_germline_alignment', 'v_germline_alignment_aa', 'd_sequence_alignment', 'd_sequence_alignment_aa',\n",
    "                'd_germline_alignment', 'd_germline_alignment_aa', 'j_sequence_alignment', 'j_sequence_alignment_aa',\n",
    "                'j_germline_alignment', 'j_germline_alignment_aa', 'junction', 'junction_length', 'junction_aa',\n",
    "                'junction_aa_length', 'v_score', 'd_score', 'j_score', 'v_cigar', 'd_cigar', 'j_cigar', 'v_support',\n",
    "                'd_support', 'j_support', 'v_identity', 'd_identity', 'j_identity', 'v_sequence_start', 'v_sequence_end',\n",
    "                'v_germline_start', 'v_germline_end', 'd_sequence_start', 'd_sequence_end', 'd_germline_start',\n",
    "                'd_germline_end', 'j_sequence_start', 'j_sequence_end', 'j_germline_start', 'j_germline_end', 'np1',\n",
    "                'np1_length', 'np2', 'np2_length', 'c_region', 'Redundancy', 'ANARCI_numbering', 'ANARCI_status', 'fwr1_aa', 'cdr1', 'cdr2', 'cdr3', 'fwr1', 'fwr2', 'fwr3', 'fwr4', 'fwr2_aa', 'fwr3_aa', 'fwr4_aa', 'fwr1_start', 'fwr1_end', 'fwr2_start', 'fwr2_end',\n",
    "                'fwr3_start', 'fwr3_end', 'fwr4_start', 'fwr4_end'\n",
    "            ]\n",
    "\n",
    "            df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "            # Replace each instance of double double quotes with a single double quote\n",
    "            metadata = metadata.replace('\"\"', '\"')\n",
    "            metadata = metadata[1:-1]\n",
    "\n",
    "            # Remove extra quotes and leading/trailing whitespace\n",
    "            metadata = metadata.replace('\"\"', '\"').strip()\n",
    "\n",
    "            start_index_chain = metadata.find('\"Chain\": \"') + len('\"Chain\": \"')  # Find the start index of the \"Chain\" value\n",
    "            end_index_chain = metadata.find('\"', start_index_chain)  # Find the end index of the \"Chain\" value\n",
    "            chain = metadata[start_index_chain:end_index_chain]  # Extract the value of \"Chain\"\n",
    "\n",
    "            start_index_disease = metadata.find('\"Disease\": \"') + len('\"Disease\": \"')  # Find the start index of the \"Disease\" value\n",
    "            end_index_disease = metadata.find('\"', start_index_disease)  # Find the end indexApologies for the abrupt cutoff in the previous message. Here is the rest of the code:\n",
    "                        # of the \"Disease\" value\n",
    "            disease = metadata[start_index_disease:end_index_disease]  # Extract the value of \"Disease\"\n",
    "\n",
    "            # Add new columns 'Chain' and 'Disease'\n",
    "            df['Chain'] = chain\n",
    "            df['Disease'] = disease\n",
    "            df['meta'] = metadata\n",
    "\n",
    "            # Append this DataFrame to the list\n",
    "            dfs.append(df)\n",
    "\n",
    "# Combine all the dataframes in the list into one big dataframe\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n",
    "df = final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80df2a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_alignment_aa</th>\n",
       "      <th>cdr1_aa</th>\n",
       "      <th>cdr2_aa</th>\n",
       "      <th>cdr3_aa</th>\n",
       "      <th>cdr1_start</th>\n",
       "      <th>cdr1_end</th>\n",
       "      <th>cdr2_start</th>\n",
       "      <th>cdr2_end</th>\n",
       "      <th>cdr3_start</th>\n",
       "      <th>cdr3_end</th>\n",
       "      <th>Chain</th>\n",
       "      <th>Disease</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VQLQESGPGLVKPSETLSLTCPVSGGSISTYYWSWIRKTPGKGLEW...</td>\n",
       "      <td>GGSISTYY</td>\n",
       "      <td>IYYSEST</td>\n",
       "      <td>ARVAGTYGGFGQLYFDY</td>\n",
       "      <td>84.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>Tonsillitis</td>\n",
       "      <td>{\"Run\": \"ERR4077966\", \"Link\": \"https://doi.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VQLQESGPGLVKPSETLSLTCNVSGGSISSGQWSWIRQPPGKGLEW...</td>\n",
       "      <td>GGSISSGQ</td>\n",
       "      <td>FYYSGST</td>\n",
       "      <td>AGDYGCRY</td>\n",
       "      <td>82.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>Tonsillitis</td>\n",
       "      <td>{\"Run\": \"ERR4077966\", \"Link\": \"https://doi.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QLQESGPGVVKPSETLSLTCTVSGGSISSGDHYWAWIRQPPGKGLE...</td>\n",
       "      <td>GGSISSGDHY</td>\n",
       "      <td>MYYSGTI</td>\n",
       "      <td>ARYVRASFDE</td>\n",
       "      <td>84.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>Tonsillitis</td>\n",
       "      <td>{\"Run\": \"ERR4077966\", \"Link\": \"https://doi.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VQLVESGGGVVQPGRSLRLSCAASGFTFNNYGMHWVRQAPGKGLEG...</td>\n",
       "      <td>GFTFNNYG</td>\n",
       "      <td>IWYDGDNK</td>\n",
       "      <td>ARAPYSTTGYFDY</td>\n",
       "      <td>85.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>Tonsillitis</td>\n",
       "      <td>{\"Run\": \"ERR4077966\", \"Link\": \"https://doi.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VQLVESGGGLVQPGGSLRLSCAASGFTFSSYEMNWVRQAPGKGLEW...</td>\n",
       "      <td>GFTFSSYE</td>\n",
       "      <td>ISSSDRTI</td>\n",
       "      <td>ARVSTQLYSQYSFDY</td>\n",
       "      <td>83.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>Tonsillitis</td>\n",
       "      <td>{\"Run\": \"ERR4077966\", \"Link\": \"https://doi.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52029</th>\n",
       "      <td>DSVKGRFTHYRDNAKNTLYMQMNSLGDEDTAIFYCARTSLYVRGSY...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARTSLYVRGSYEHY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>SARS-COV-2</td>\n",
       "      <td>{\"Run\": \"SRR12326777\", \"Link\": \"https://dx.doi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52030</th>\n",
       "      <td>YYNPSLHSRVTLSIHTSKRQFSLKLTSVTAADTAIYFCARGPPRLG...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARGPPRLGFDY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>SARS-COV-2</td>\n",
       "      <td>{\"Run\": \"SRR12326777\", \"Link\": \"https://dx.doi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52031</th>\n",
       "      <td>YYNPSLNSRVTLSINTSKRQFSLKLTSVTAADTAIYFCARGPPRLG...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARGPPRLGFDY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>SARS-COV-2</td>\n",
       "      <td>{\"Run\": \"SRR12326777\", \"Link\": \"https://dx.doi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52032</th>\n",
       "      <td>TYYHPSLNSRVTLSISTSKRQFSLKLTSVTAADTAIYFCARGPPRL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>ARGPPRLGFDY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>SARS-COV-2</td>\n",
       "      <td>{\"Run\": \"SRR12326777\", \"Link\": \"https://dx.doi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52033</th>\n",
       "      <td>NADSVKGRFTNSRDNAKNSLYLQMTSLRAEDTAVYYCAIIPGTTGL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIIPGTTGLRRYFDL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>SARS-COV-2</td>\n",
       "      <td>{\"Run\": \"SRR12326777\", \"Link\": \"https://dx.doi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52034 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   sequence_alignment_aa     cdr1_aa   cdr2_aa            cdr3_aa  cdr1_start  cdr1_end  cdr2_start  cdr2_end  cdr3_start  cdr3_end  Chain      Disease                                               meta\n",
       "0      VQLQESGPGLVKPSETLSLTCPVSGGSISTYYWSWIRKTPGKGLEW...    GGSISTYY   IYYSEST  ARVAGTYGGFGQLYFDY        84.0     107.0       159.0     179.0       294.0     344.0  Heavy  Tonsillitis  {\"Run\": \"ERR4077966\", \"Link\": \"https://doi.org...\n",
       "1      VQLQESGPGLVKPSETLSLTCNVSGGSISSGQWSWIRQPPGKGLEW...    GGSISSGQ   FYYSGST           AGDYGCRY        82.0     105.0       157.0     177.0       292.0     315.0  Heavy  Tonsillitis  {\"Run\": \"ERR4077966\", \"Link\": \"https://doi.org...\n",
       "2      QLQESGPGVVKPSETLSLTCTVSGGSISSGDHYWAWIRQPPGKGLE...  GGSISSGDHY   MYYSGTI         ARYVRASFDE        84.0     113.0       165.0     185.0       300.0     329.0  Heavy  Tonsillitis  {\"Run\": \"ERR4077966\", \"Link\": \"https://doi.org...\n",
       "3      VQLVESGGGVVQPGRSLRLSCAASGFTFNNYGMHWVRQAPGKGLEG...    GFTFNNYG  IWYDGDNK      ARAPYSTTGYFDY        85.0     108.0       160.0     183.0       298.0     336.0  Heavy  Tonsillitis  {\"Run\": \"ERR4077966\", \"Link\": \"https://doi.org...\n",
       "4      VQLVESGGGLVQPGGSLRLSCAASGFTFSSYEMNWVRQAPGKGLEW...    GFTFSSYE  ISSSDRTI    ARVSTQLYSQYSFDY        83.0     106.0       158.0     181.0       296.0     340.0  Heavy  Tonsillitis  {\"Run\": \"ERR4077966\", \"Link\": \"https://doi.org...\n",
       "...                                                  ...         ...       ...                ...         ...       ...         ...       ...         ...       ...    ...          ...                                                ...\n",
       "52029  DSVKGRFTHYRDNAKNTLYMQMNSLGDEDTAIFYCARTSLYVRGSY...         NaN       NaN     ARTSLYVRGSYEHY         NaN       NaN         NaN       NaN       112.0     153.0  Heavy   SARS-COV-2  {\"Run\": \"SRR12326777\", \"Link\": \"https://dx.doi...\n",
       "52030  YYNPSLHSRVTLSIHTSKRQFSLKLTSVTAADTAIYFCARGPPRLG...         NaN       NaN        ARGPPRLGFDY         NaN       NaN         2.0       3.0       118.0     150.0  Heavy   SARS-COV-2  {\"Run\": \"SRR12326777\", \"Link\": \"https://dx.doi...\n",
       "52031  YYNPSLNSRVTLSINTSKRQFSLKLTSVTAADTAIYFCARGPPRLG...         NaN       NaN        ARGPPRLGFDY         NaN       NaN         2.0       3.0       118.0     150.0  Heavy   SARS-COV-2  {\"Run\": \"SRR12326777\", \"Link\": \"https://dx.doi...\n",
       "52032  TYYHPSLNSRVTLSISTSKRQFSLKLTSVTAADTAIYFCARGPPRL...         NaN         T        ARGPPRLGFDY         NaN       NaN         1.0       3.0       118.0     150.0  Heavy   SARS-COV-2  {\"Run\": \"SRR12326777\", \"Link\": \"https://dx.doi...\n",
       "52033  NADSVKGRFTNSRDNAKNSLYLQMTSLRAEDTAVYYCAIIPGTTGL...         NaN       NaN    AIIPGTTGLRRYFDL         NaN       NaN         NaN       NaN       115.0     159.0  Heavy   SARS-COV-2  {\"Run\": \"SRR12326777\", \"Link\": \"https://dx.doi...\n",
       "\n",
       "[52034 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55a45ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sequence     cdr1_aa   cdr2_aa            cdr3_aa  cdr1_start  cdr1_end  cdr2_start  cdr2_end  cdr3_start  cdr3_end  Chain      Disease                                               meta\n",
      "0  VQLQESGPGLVKPSETLSLTCPVSGGSISTYYWSWIRKTPGKGLEW...    GGSISTYY   IYYSEST  ARVAGTYGGFGQLYFDY        84.0     107.0       159.0     179.0       294.0     344.0  Heavy  Tonsillitis  {\"Run\": \"ERR4077966\", \"Link\": \"https://doi.org...\n",
      "1  VQLQESGPGLVKPSETLSLTCNVSGGSISSGQWSWIRQPPGKGLEW...    GGSISSGQ   FYYSGST           AGDYGCRY        82.0     105.0       157.0     177.0       292.0     315.0  Heavy  Tonsillitis  {\"Run\": \"ERR4077966\", \"Link\": \"https://doi.org...\n",
      "2  QLQESGPGVVKPSETLSLTCTVSGGSISSGDHYWAWIRQPPGKGLE...  GGSISSGDHY   MYYSGTI         ARYVRASFDE        84.0     113.0       165.0     185.0       300.0     329.0  Heavy  Tonsillitis  {\"Run\": \"ERR4077966\", \"Link\": \"https://doi.org...\n",
      "3  VQLVESGGGVVQPGRSLRLSCAASGFTFNNYGMHWVRQAPGKGLEG...    GFTFNNYG  IWYDGDNK      ARAPYSTTGYFDY        85.0     108.0       160.0     183.0       298.0     336.0  Heavy  Tonsillitis  {\"Run\": \"ERR4077966\", \"Link\": \"https://doi.org...\n",
      "4  VQLVESGGGLVQPGGSLRLSCAASGFTFSSYEMNWVRQAPGKGLEW...    GFTFSSYE  ISSSDRTI    ARVSTQLYSQYSFDY        83.0     106.0       158.0     181.0       296.0     340.0  Heavy  Tonsillitis  {\"Run\": \"ERR4077966\", \"Link\": \"https://doi.org...\n",
      "52034\n",
      "0        122\n",
      "1        113\n",
      "2        116\n",
      "3        119\n",
      "4        121\n",
      "        ... \n",
      "52029     60\n",
      "52030     60\n",
      "52031     60\n",
      "52032     61\n",
      "52033     63\n",
      "Name: sequence_length, Length: 52034, dtype: int64\n",
      "52034\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Rename the column\n",
    "df = df.rename(columns={'sequence_alignment_aa': 'sequence'})\n",
    "\n",
    "# Step 2: Make 'sequence' the first column\n",
    "cols = df.columns.tolist()\n",
    "cols.insert(0, cols.pop(cols.index('sequence')))\n",
    "df = df[cols]\n",
    "\n",
    "print(df.head())\n",
    "print(len(df))\n",
    "df['sequence_length'] = df['sequence'].apply(len)\n",
    "print(df['sequence_length'])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c226be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>cdr1_aa</th>\n",
       "      <th>cdr2_aa</th>\n",
       "      <th>cdr3_aa</th>\n",
       "      <th>cdr1_start</th>\n",
       "      <th>cdr1_end</th>\n",
       "      <th>Chain</th>\n",
       "      <th>Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VQLQESGPGLVKPSETLSLTCPVSGGSISTYYWSWIRKTPGKGLEW...</td>\n",
       "      <td>GGSISTYY</td>\n",
       "      <td>IYYSEST</td>\n",
       "      <td>ARVAGTYGGFGQLYFDY</td>\n",
       "      <td>84.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>Tonsillitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VQLQESGPGLVKPSETLSLTCNVSGGSISSGQWSWIRQPPGKGLEW...</td>\n",
       "      <td>GGSISSGQ</td>\n",
       "      <td>FYYSGST</td>\n",
       "      <td>AGDYGCRY</td>\n",
       "      <td>82.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>Tonsillitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QLQESGPGVVKPSETLSLTCTVSGGSISSGDHYWAWIRQPPGKGLE...</td>\n",
       "      <td>GGSISSGDHY</td>\n",
       "      <td>MYYSGTI</td>\n",
       "      <td>ARYVRASFDE</td>\n",
       "      <td>84.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>Tonsillitis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence     cdr1_aa  cdr2_aa            cdr3_aa  cdr1_start  cdr1_end  Chain      Disease\n",
       "0  VQLQESGPGLVKPSETLSLTCPVSGGSISTYYWSWIRKTPGKGLEW...    GGSISTYY  IYYSEST  ARVAGTYGGFGQLYFDY        84.0     107.0  Heavy  Tonsillitis\n",
       "1  VQLQESGPGLVKPSETLSLTCNVSGGSISSGQWSWIRQPPGKGLEW...    GGSISSGQ  FYYSGST           AGDYGCRY        82.0     105.0  Heavy  Tonsillitis\n",
       "2  QLQESGPGVVKPSETLSLTCTVSGGSISSGDHYWAWIRQPPGKGLE...  GGSISSGDHY  MYYSGTI         ARYVRASFDE        84.0     113.0  Heavy  Tonsillitis"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([ 'cdr2_start', 'cdr2_end', 'cdr3_start', 'cdr3_end', 'meta', 'sequence_length'], axis=1, inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b2e32d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_cdr_to_sequence(full_seq, cdr1_seq, cdr2_seq, cdr3_seq):\n",
    "    mapping = [0]*len(full_seq)\n",
    "    for cdr_seq, num in zip([cdr1_seq, cdr2_seq, cdr3_seq], [1, 2, 3]):\n",
    "        cdr_start = full_seq.find(cdr_seq)\n",
    "        if cdr_start != -1:\n",
    "            for i in range(len(cdr_seq)):\n",
    "                mapping[cdr_start + i] = num\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0b045ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sequence'] = df['sequence'].astype(str)\n",
    "df['cdr1_aa'] = df['cdr1_aa'].astype(str)\n",
    "df['cdr2_aa'] = df['cdr2_aa'].astype(str)\n",
    "df['cdr3_aa'] = df['cdr3_aa'].astype(str)\n",
    "df = df.dropna(subset=['sequence', 'cdr1_aa', 'cdr2_aa', 'cdr3_aa'])\n",
    "\n",
    "df['sequence_classification'] = df.apply(lambda row: map_cdr_to_sequence(row['sequence'], row['cdr1_aa'], row['cdr2_aa'], row['cdr3_aa']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1367bfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sequences, test_sequences, train_labels, test_labels = train_test_split(df['sequence'], df['sequence_classification'], test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b779e128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "\n",
    "train_tokenized = tokenizer(list(train_sequences))\n",
    "test_tokenized = tokenizer(list(test_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1484d13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_tokenized)\n",
    "test_dataset = Dataset.from_dict(test_tokenized)\n",
    "\n",
    "train_dataset = train_dataset.add_column(\"labels\", train_labels)\n",
    "test_dataset = test_dataset.add_column(\"labels\", test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2045e959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0,\n",
       "  6,\n",
       "  6,\n",
       "  8,\n",
       "  4,\n",
       "  10,\n",
       "  4,\n",
       "  8,\n",
       "  23,\n",
       "  5,\n",
       "  5,\n",
       "  8,\n",
       "  6,\n",
       "  18,\n",
       "  12,\n",
       "  18,\n",
       "  8,\n",
       "  8,\n",
       "  19,\n",
       "  5,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  7,\n",
       "  10,\n",
       "  16,\n",
       "  5,\n",
       "  14,\n",
       "  6,\n",
       "  15,\n",
       "  6,\n",
       "  4,\n",
       "  9,\n",
       "  22,\n",
       "  7,\n",
       "  5,\n",
       "  7,\n",
       "  12,\n",
       "  8,\n",
       "  8,\n",
       "  13,\n",
       "  6,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  19,\n",
       "  19,\n",
       "  5,\n",
       "  13,\n",
       "  8,\n",
       "  7,\n",
       "  15,\n",
       "  6,\n",
       "  10,\n",
       "  18,\n",
       "  11,\n",
       "  12,\n",
       "  8,\n",
       "  10,\n",
       "  13,\n",
       "  17,\n",
       "  8,\n",
       "  15,\n",
       "  17,\n",
       "  14,\n",
       "  4,\n",
       "  18,\n",
       "  4,\n",
       "  16,\n",
       "  20,\n",
       "  8,\n",
       "  8,\n",
       "  4,\n",
       "  10,\n",
       "  7,\n",
       "  9,\n",
       "  13,\n",
       "  11,\n",
       "  5,\n",
       "  4,\n",
       "  19,\n",
       "  19,\n",
       "  23,\n",
       "  5,\n",
       "  10,\n",
       "  9,\n",
       "  13,\n",
       "  19,\n",
       "  19,\n",
       "  6,\n",
       "  10,\n",
       "  6,\n",
       "  7,\n",
       "  4,\n",
       "  13,\n",
       "  5,\n",
       "  4,\n",
       "  13,\n",
       "  12,\n",
       "  22,\n",
       "  6,\n",
       "  16,\n",
       "  6,\n",
       "  11,\n",
       "  20,\n",
       "  7,\n",
       "  11,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  2],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ac00893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccbc417f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Set the device      \n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a75500a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    0: \"Non-CDR\",\n",
    "    1: \"CDR1\",\n",
    "    2: \"CDR2\",\n",
    "    3: \"CDR3\",\n",
    "}\n",
    "label2id = {\n",
    "    \"Non-CDR\": 0,\n",
    "    \"CDR1\": 1,\n",
    "    \"CDR2\": 2,\n",
    "    \"CDR3\": 3,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a35ba17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/esm2_t6_8M_UR50D were not used when initializing EsmForTokenClassification: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing EsmForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EsmForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of EsmForTokenClassification were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EsmForTokenClassification(\n",
       "  (esm): EsmModel(\n",
       "    (embeddings): EsmEmbeddings(\n",
       "      (word_embeddings): Embedding(33, 320, padding_idx=1)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (position_embeddings): Embedding(1026, 320, padding_idx=1)\n",
       "    )\n",
       "    (encoder): EsmEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "              (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "              (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (emb_layer_norm_after): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (contact_head): EsmContactPredictionHead(\n",
       "      (regression): Linear(in_features=120, out_features=1, bias=True)\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (classifier): Linear(in_features=320, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"facebook/esm2_t6_8M_UR50D\", num_labels=4)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53568a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "import numpy as np\n",
    "\n",
    "metric = load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    labels = labels.reshape((-1,))\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    predictions = predictions.reshape((-1,))\n",
    "    predictions = predictions[labels!=-100]\n",
    "    labels = labels[labels!=-100]\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa51d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=directory,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.001,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    use_mps_device=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "caa737bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewocanas/Desktop/CDR-Classifier/env/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/Users/matthewocanas/Desktop/CDR-Classifier/env/lib/python3.8/site-packages/transformers/models/esm/modeling_esm.py:217: UserWarning: MPS: no support for int64 reduction ops, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/ReduceOps.mm:144.)\n",
      "  src_lengths = attention_mask.sum(-1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 17:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.999792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.999889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.999914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3660, training_loss=0.011272839177908793, metrics={'train_runtime': 1020.9565, 'train_samples_per_second': 114.672, 'train_steps_per_second': 3.585, 'total_flos': 677492713481010.0, 'train_loss': 0.011272839177908793, 'epoch': 3.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    "    \n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9db3fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_array(input_array):\n",
    "    output_array = []\n",
    "    cdr_positions = {1: [None, None], 2: [None, None], 3: [None, None]}\n",
    "\n",
    "    for idx, label in enumerate(input_array):\n",
    "        if label == 'LABEL_0':\n",
    "            output_array.append('0')\n",
    "        elif label in ['LABEL_1', 'LABEL_2', 'LABEL_3']:\n",
    "            label_num = int(label[-1])\n",
    "            output_array.append(str(label_num))\n",
    "            if cdr_positions[label_num][0] is None:\n",
    "                cdr_positions[label_num][0] = idx\n",
    "            cdr_positions[label_num][1] = idx\n",
    "\n",
    "    output_string = ''.join(output_array)\n",
    "    return output_string, cdr_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f36004b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000000000000000000000000111111110000000000000000022222222000000000000000000000000000000000000003333333333330000000000000\n",
      "CDR1: GYSFTDYY\n",
      "CDR2: INPKSGGT\n",
      "CDR3: VKDCGSGGLRDF\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "sequence = 'QVQLVQSGAEVRKPGASVKVSCKASGYSFTDYYMHWVRQAPGQGLEWMGWINPKSGGTNYAQRFQGRVTMTGDTSISAAYMDLASLTSDDTAVYYCVKDCGSGGLRDFWGQGTTVTVSS'\n",
    "inputs = tokenizer(sequence, return_tensors=\"pt\").to(device)\n",
    "logits = model(**inputs).logits\n",
    "predicted_token_class_ids = torch.argmax(logits, dim=-1)\n",
    "predicted_token_class = [model.config.id2label[t] for t in predicted_token_class_ids[0].tolist()]\n",
    "\n",
    "output_string, cdr_positions = convert_array(predicted_token_class)\n",
    "\n",
    "print(output_string)\n",
    "\n",
    "for cdr, positions in cdr_positions.items():\n",
    "    start, end = positions\n",
    "    if start is not None and end is not None:\n",
    "        cdr_sequence = sequence[start:end+1]\n",
    "        print(f\"CDR{cdr}: {cdr_sequence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41ce8638",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
